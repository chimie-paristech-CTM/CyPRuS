{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k8LmvM9Dago_",
    "outputId": "ae1f146c-0a2d-4600-ce2a-cbf4e1ae20e3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### If your run the notebooks on Google Colab uncomment these lines to install required packages\n",
    "\n",
    "#!pip install rdkit\n",
    "#!pip install chemprop\n",
    "#!pip install matplotlib\n",
    "#!pip install seaborn xgboost hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "vwTiHWFIal6r"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/python/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from random import sample, seed, shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import six\n",
    "from rdkit import rdBase\n",
    "from rdkit import RDLogger\n",
    "\n",
    "# Suppress RDKit warnings\n",
    "rdBase.DisableLog('rdApp.*')\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "#utility functions : prepare the data\n",
    "from model_fp_selection.lib.utils import prepare_df_morgan, prepare_df_rdkit, swap_identical_ligands, prepare_df_chemeleon, convert_to_float, prepare_df\n",
    "from model_fp_selection.lib.utils import drop_duplicates, average_duplicates, calc_desc, get_ligands_dict\n",
    "\n",
    "#utility functions : CV and results\n",
    "from model_fp_selection.lib.utils import obtain_metrics, plot_cv_results\n",
    "from model_fp_selection.lib.utils import df_split, get_indices_doi, get_indices_scaff, get_indices_chemeleon, get_indices_chemeleon_DOI, get_indices_chemeleon_scaff\n",
    "from model_fp_selection.lib.utils import generate_scaffold, scaffold_to_smiles\n",
    "from model_fp_selection.lib.utils import ligands_permutation, cross_validation, prepare_train_set, cross_validation_chemeleon\n",
    "\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, DataStructs, Draw\n",
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, median_absolute_error, PredictionErrorDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Encoding categorical Data\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Regressors\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "#Pipelines and other model constructions\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "#np.random.seed(42)\n",
    "#seed(42)\n",
    "\n",
    "#Specific to Scaffold Splitting\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "from collections import defaultdict\n",
    "import pickle as pkl\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "from itertools import *\n",
    "\n",
    "from model_fp_selection.lib.cross_val_both_models import cross_val_2_models\n",
    "\n",
    "from model_fp_selection.chemeleon_fingerprint import CheMeleonFingerprint\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from lightning import pytorch as pl\n",
    "\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as torch_nn\n",
    "\n",
    "from chemprop import data, models, featurizers, nn\n",
    "\n",
    "import time\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import Callback\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fRdmd4Oaazrt",
    "outputId": "d46ed453-a30e-47b8-8afc-b899ed72b3c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('chemeleon_mp.pt', <http.client.HTTPMessage at 0x7fa871c47d90>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "\n",
    "urlretrieve(\n",
    "    r\"https://zenodo.org/records/15460715/files/chemeleon_mp.pt\",\n",
    "    \"chemeleon_mp.pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct workflow to save finetuned weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "pl.seed_everything(SEED, workers=True)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input=pd.read_csv('./ruthenium_complexes_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training dataset after cleaning duplicates, before adding permutations : 718\n"
     ]
    }
   ],
   "source": [
    "smiles_column = \"SMILES\"\n",
    "target_columns = [\"pIC50\"]\n",
    "\n",
    "df = prepare_df(df_input)\n",
    "df = average_duplicates(df, \"Ligands_Dict\", \"pIC50\")\n",
    "\n",
    "df[\"SMILES\"] = df.L1 + \".\" + df.L2 + \".\" + df.L3\n",
    "df[\"ID\"] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "smis = df[smiles_column].values\n",
    "ys   = df[target_columns].values\n",
    "\n",
    "all_data = [\n",
    "    data.MoleculeDatapoint.from_smi(smi, y)\n",
    "    for smi, y in zip(smis, ys)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = featurizers.SimpleMoleculeMolGraphFeaturizer()\n",
    "\n",
    "full_dset = data.MoleculeDataset(all_data, featurizer)\n",
    "scaler = full_dset.normalize_targets()\n",
    "\n",
    "train_loader = data.build_dataloader(\n",
    "    full_dset,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "chemeleon_ckpt = torch.load(\"chemeleon_mp.pt\", weights_only=True)\n",
    "\n",
    "mp = nn.BondMessagePassing(**chemeleon_ckpt[\"hyper_parameters\"])\n",
    "mp.load_state_dict(chemeleon_ckpt[\"state_dict\"])\n",
    "\n",
    "agg = nn.MeanAggregation()\n",
    "\n",
    "output_transform = nn.UnscaleTransform.from_standard_scaler(scaler)\n",
    "\n",
    "ffn = nn.RegressionFFN(\n",
    "    input_dim=mp.output_dim,\n",
    "    n_layers=3,\n",
    "    hidden_dim=400,\n",
    "    dropout=0.1,\n",
    "    output_transform=output_transform\n",
    ")\n",
    "mpnn = models.MPNN(\n",
    "    mp,\n",
    "    agg,\n",
    "    ffn,\n",
    "    batch_norm=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/python/lib/python3.13/site-packages/lightning/pytorch/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/opt/python/lib/python3.13/site-packages/lightning/pytorch/utilities/_pytree.py:21: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.\n",
      "/opt/python/lib/python3.13/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:434: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=71` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name            </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type               </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ message_passing │ BondMessagePassing │  8.7 M │ train │     0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ agg             │ MeanAggregation    │      0 │ train │     0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ bn              │ Identity           │      0 │ train │     0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ predictor       │ RegressionFFN      │  1.1 M │ train │     0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ X_d_transform   │ Identity           │      0 │ train │     0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>│ metrics         │ ModuleList         │      0 │ train │     0 │\n",
       "└───┴─────────────────┴────────────────────┴────────┴───────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName           \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType              \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ message_passing │ BondMessagePassing │  8.7 M │ train │     0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ agg             │ MeanAggregation    │      0 │ train │     0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ bn              │ Identity           │      0 │ train │     0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ predictor       │ RegressionFFN      │  1.1 M │ train │     0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ X_d_transform   │ Identity           │      0 │ train │     0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m5\u001b[0m\u001b[2m \u001b[0m│ metrics         │ ModuleList         │      0 │ train │     0 │\n",
       "└───┴─────────────────┴────────────────────┴────────┴───────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 9.9 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 9.9 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 39                                                                         \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 28                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 9.9 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 9.9 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 39                                                                         \n",
       "\u001b[1mModules in train mode\u001b[0m: 28                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/opt/python/lib/python3.13/site-packages/rich/live.py:260: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/opt/python/lib/python3.13/site-packages/rich/live.py:260: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    max_epochs=20,\n",
    "    logger=False,\n",
    "    enable_checkpointing=False\n",
    ")\n",
    "\n",
    "trainer.fit(mpnn, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mpnn.state_dict(), \"final_mpnn_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(scaler, \"target_scaler.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL sklearn.preprocessing._data.StandardScaler was not an allowed global by default. Please use `torch.serialization.add_safe_globals([sklearn.preprocessing._data.StandardScaler])` or the `torch.serialization.safe_globals([sklearn.preprocessing._data.StandardScaler])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnpicklingError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[80]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m MODEL_PATH = \u001b[33m\"\u001b[39m\u001b[33mfinal_mpnn_weights.pth\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m SCALER_PATH = \u001b[33m\"\u001b[39m\u001b[33mtarget_scaler.pth\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m scaler = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSCALER_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/torch/serialization.py:1548\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1540\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[32m   1541\u001b[39m                     opened_zipfile,\n\u001b[32m   1542\u001b[39m                     map_location,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1545\u001b[39m                     **pickle_load_args,\n\u001b[32m   1546\u001b[39m                 )\n\u001b[32m   1547\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle.UnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1548\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle.UnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1549\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[32m   1550\u001b[39m             opened_zipfile,\n\u001b[32m   1551\u001b[39m             map_location,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1554\u001b[39m             **pickle_load_args,\n\u001b[32m   1555\u001b[39m         )\n\u001b[32m   1556\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n",
      "\u001b[31mUnpicklingError\u001b[39m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL sklearn.preprocessing._data.StandardScaler was not an allowed global by default. Please use `torch.serialization.add_safe_globals([sklearn.preprocessing._data.StandardScaler])` or the `torch.serialization.safe_globals([sklearn.preprocessing._data.StandardScaler])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"final_mpnn_weights.pth\"\n",
    "SCALER_PATH = \"target_scaler.pth\"\n",
    "\n",
    "scaler = torch.load(SCALER_PATH, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"synthesized_complexes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"SMILES\"] = df_test[\"L1\"] + \".\" + df_test[\"L2\"] + \".\" + df_test[\"L3\"]\n",
    "df_test[\"ID\"] = df_test.index\n",
    "ys = [None] * len(df_test)\n",
    "test_data = [\n",
    "    data.MoleculeDatapoint.from_smi(smi, y)\n",
    "    for smi, y in zip(df_test[\"SMILES\"], ys)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/opt/python/lib/python3.13/site-packages/rich/live.py:260: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/opt/python/lib/python3.13/site-packages/rich/live.py:260: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/python/lib/python3.13/site-packages/lightning/pytorch/utilities/_pytree.py:21: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.\n",
      "/opt/python/lib/python3.13/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:434: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=71` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "featurizer = featurizers.SimpleMoleculeMolGraphFeaturizer()\n",
    "\n",
    "test_dset = data.MoleculeDataset(test_data, featurizer)\n",
    "\n",
    "test_loader = data.build_dataloader(\n",
    "    test_dset,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "# Load CheMeleon MP backbone\n",
    "chemeleon_ckpt = torch.load(\"chemeleon_mp.pt\", weights_only=True)\n",
    "\n",
    "mp = nn.BondMessagePassing(**chemeleon_ckpt[\"hyper_parameters\"])\n",
    "mp.load_state_dict(chemeleon_ckpt[\"state_dict\"])\n",
    "\n",
    "agg = nn.MeanAggregation()\n",
    "\n",
    "output_transform = nn.UnscaleTransform.from_standard_scaler(scaler)\n",
    "\n",
    "ffn = nn.RegressionFFN(\n",
    "    input_dim=mp.output_dim,\n",
    "    n_layers=3,\n",
    "    hidden_dim=400,\n",
    "    dropout=0.1,\n",
    "    output_transform=output_transform\n",
    ")\n",
    "\n",
    "mpnn = models.MPNN(mp, agg, ffn, batch_norm=False)\n",
    "\n",
    "mpnn.load_state_dict(torch.load(MODEL_PATH))\n",
    "mpnn.eval()\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=False\n",
    ")\n",
    "\n",
    "preds = trainer.predict(mpnn, test_loader)\n",
    "preds = torch.cat(preds).cpu().numpy().squeeze()\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"ID\": df_test[\"ID\"],\n",
    "    \"SMILES\": df_test[\"SMILES\"],\n",
    "    \"pIC50_pred\": preds\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>pIC50_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>C1(C2=CC=CC=C2)=CC=NC3=C1C=CC4=C3N=CC=C4C5=CC=...</td>\n",
       "      <td>5.590017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>C1(C2=NC=CC=C2)=NC=CC=C1.C1(C2=NC=CC=C2)=NC=CC...</td>\n",
       "      <td>4.516929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>C1(C2=NC=CC=C2)=NC=CC=C1.C1(C2=NC=CC=C2)=NC=CC...</td>\n",
       "      <td>4.065144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>C12=NC=CC=C1C=CC3=C2N=CC=C3.C12=NC=CC=C1C=CC3=...</td>\n",
       "      <td>6.331344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>C12=NC=CC=C1C=CC3=C2N=CC=C3.C12=NC=CC=C1C=CC3=...</td>\n",
       "      <td>6.186633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>C1(C2=CC=CC=N2)=NC=CC=C1.C1(C2=CC=CC=N2)=NC=CC...</td>\n",
       "      <td>4.147353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>C12=NC=CC=C1C=CC3=C2N=CC=C3.C12=NC=CC=C1C=CC3=...</td>\n",
       "      <td>5.377989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                             SMILES  pIC50_pred\n",
       "0   0  C1(C2=CC=CC=C2)=CC=NC3=C1C=CC4=C3N=CC=C4C5=CC=...    5.590017\n",
       "1   1  C1(C2=NC=CC=C2)=NC=CC=C1.C1(C2=NC=CC=C2)=NC=CC...    4.516929\n",
       "2   2  C1(C2=NC=CC=C2)=NC=CC=C1.C1(C2=NC=CC=C2)=NC=CC...    4.065144\n",
       "3   3  C12=NC=CC=C1C=CC3=C2N=CC=C3.C12=NC=CC=C1C=CC3=...    6.331344\n",
       "4   4  C12=NC=CC=C1C=CC3=C2N=CC=C3.C12=NC=CC=C1C=CC3=...    6.186633\n",
       "5   5  C1(C2=CC=CC=N2)=NC=CC=C1.C1(C2=CC=CC=N2)=NC=CC...    4.147353\n",
       "6   6  C12=NC=CC=C1C=CC3=C2N=CC=C3.C12=NC=CC=C1C=CC3=...    5.377989"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
